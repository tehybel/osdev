

Time: 13-15, 13-15:15, 21:30-00, 

The next task is figuring out how to get graphics working. I'll keep some
unpolished notes here.

Some links:

	https://web.archive.org/web/20150725135958/http://web.mit.edu/amdragon/www/pubs/sqrtx-6.828.html
	http://wiki.osdev.org/Graphics_stack
	http://wiki.osdev.org/VESA_Video_Modes 
	http://wiki.osdev.org/User:Omarrx024/VESA_Tutorial
	http://wiki.osdev.org/VGA_Hardware
	http://wiki.osdev.org/How_do_I_set_a_graphics_mode
	http://wiki.osdev.org/GUI
	https://en.wikipedia.org/wiki/VESA_BIOS_Extensions
	https://wiki.gentoo.org/wiki/QEMU/Options#Graphics_card


VESA is apparently a standard that lets you interface uniformly with a number
of different graphics cards. So we just need to write a VESA driver.

First, though, I need an overview of how graphics are actually drawn on the
screen. I have no clue yet how it all works.

Maybe we want VGA rather than VESA; according to a forum thread, it's the
easier option to start with.

	Many video cards have two interfaces, one VGA interface for low
	resolutions, and the VESA VBE interface for higher resolutions.
	Alternatively, you can write your own code to directly deal with the
	graphics hardware.
		- http://wiki.osdev.org/How_do_I_set_a_graphics_mode


What I'm really missing at the moment is an overview of how graphics work. I
have *no clue* how these colored pixels are showing up on my screen.

This page gives a bit of an overview:

	http://wiki.osdev.org/Graphics_stack

Apparently the device driver interacts with the graphics card and can only do
very simple things like "draw a pixel here". Instead of writing a driver for
every card, you instead write a driver for the VESA or VGA interface, which
most cards support. VGA is simpler, but lower resolution, than VESA.

Once you can draw pixels, you can create a stack on top: a library to draw
lines and rectangles, and then you can draw "widgets" like windows and
buttons. The window manager uses these widget-drawing functions and manages
where windows are placed on screen.

We're also going to need a driver for a USB mouse.

Here are more details on how to actually implement this from the bottom up:

	http://wiki.osdev.org/GUI



According to that page:

	The tutorial assumes ... the video resolution has been set using VBE in a
	linear frame buffer
	
	The kernel should probe the BIOS for the VBE Mode Info Block (see Getting
	VBE Mode Info), which returns information about the established video
	resolution mode.

So let's figure out how to do that.


According to this page:

	http://wiki.osdev.org/Getting_VBE_Mode_Info

We need to use int 0x10. But that's not available in protected mode.

So we need to call it from real mode, before we switch to protected mode.

We need to use function 0x4F02, with a value of 0xC118 (?) to create a linear
frame buffer, then use 0x4F01 to get the physical address of the LFB. More
details here:

	http://wiki.osdev.org/Getting_VBE_Mode_Info

But to use 0x4F02 ("Set Video Mode") we first need to pick a mode.

The example code on that page uses virtual86 interrupts. What's that?

According to this page:

	http://wiki.osdev.org/Virtual_8086_Mode

It's a way to emulate real mode from within protected mode. You set a flag in
the EFLAGS register, and then you're emulating real mode.

It seems that we need the ability to run v86 (virtual-8086) processes, because
then we can simply spawn a process which switches video modes for us.

So that should be the first step.

How do you enter v86? By setting a flag in the eflags register before doing an
iret. So that should be doable..

I've added a mode that does this, but now the created process segfaults with a
page fault upon the first instruction at 0x20. Why is it at 0x20? The entry
point is 0x800020. I guess registers are 16-bit now, then.

How do we compile for v86? Turns out that gcc can't do that. We need an 8086
compiler. But I think we're going off track, now.

Now that I think about it, we just need to be able to perform the int 0x10
instruction, nothing else. So we need a "v86int" function.

To switch to and from v86 mode, we can have syscalls that do this.

But actually this is going to be really hard. We need access to physical
addresses inside the function which sets up modes. We only have that from the
kernel.

It would be far easier to do all this work directly in the early kernel code,
rather than having to switch to v86 mode.



So let's try to do that instead.


...

Nope, that's really hard, too.

I guess we do want to be able to switch to v86 after all.



So I propose the following syscall:

	sys_v86

which switches to virtual-8086 mode by setting the flag in eflags. It will
then set $ip=0, $sp=0x1000, and go from there. So the program must first have
copied the right code into address 0, and have mapped 0x1000, too.

How does the program "get back"? The OS can remember the next instruction's
address. When the program is done running in v86 mode, it will do..
something.. and then the OS restores its state.

What will the program do to signal that it wants to return to normal mode? It
could issue a breakpoint instruction.

That should work. Maybe.


........

This turns out to be a total mess. Switching to virtual-8086 mode isn't easy.
And then, interrupts are handled in a very complicated manner. We can't just
do an "int 0x10", because that will trigger a GPF, going via the IDT. There
should be a way to make the interrupt work as it would in real mode, but it's
complicated.


http://f.osdev.org/viewtopic.php?f=1&t=11108




- others must have done this already. Can I find source somewhere to read?

- 


